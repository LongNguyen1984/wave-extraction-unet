{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image augmentation\n",
    "import cv2\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import CSVLogger\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "import numpy as np\n",
    "import model\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 51 images belonging to 2 classes.\n",
      "Found 51 images belonging to 2 classes.\n",
      "Found 14 images belonging to 2 classes.\n",
      "Found 14 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Creating image generators \n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "        \n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_image_generator = train_datagen.flow_from_directory('train_frames', batch_size = 4)\n",
    "\n",
    "train_mask_generator = train_datagen.flow_from_directory('train_masks', batch_size = 4)\n",
    "\n",
    "val_image_generator = val_datagen.flow_from_directory('val_frames', batch_size = 4)\n",
    "\n",
    "val_mask_generator = val_datagen.flow_from_directory('val_masks', batch_size = 4)\n",
    "\n",
    "train_gen = zip(train_image_generator, train_mask_generator)\n",
    "val_gen = zip(val_image_generator, val_mask_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'.ipynb_checkpoints': 0, 'train': 1}\n",
      "<class 'zip'>\n"
     ]
    }
   ],
   "source": [
    "# Figure out class weights\n",
    "print(train_image_generator.class_indices)\n",
    "class_weights = {0: 1.,\n",
    "                 1: 197.}\n",
    "\n",
    "print(type(train_gen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 8 into shape (512,512,3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-a8de794050ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots_adjust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhspace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwspace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gray\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 8 into shape (512,512,3)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check to see if mask is saved correctly for training set\n",
    "image_batch, mask_batch = next(train_gen)\n",
    "\n",
    "r = random.randint(0, len(image_batch)-1)\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "ax.imshow(image_batch[r].reshape(SIZE, SIZE, 3))\n",
    "ax = fig.add_subplot(1, 2, 2)\n",
    "ax.imshow(np.reshape(mask_batch[r], (SIZE, SIZE)), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to see if mask is saved correctly for validation set\n",
    "# image_batch, mask_batch = next(val_gen)\n",
    "\n",
    "# r = random.randint(0, len(image_batch)-1)\n",
    "\n",
    "# fig = plt.figure()\n",
    "# fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "# ax = fig.add_subplot(1, 2, 1)\n",
    "# ax.imshow(image_batch[r].reshape(SIZE, SIZE, 3))\n",
    "# ax = fig.add_subplot(1, 2, 2)\n",
    "# ax.imshow(np.reshape(mask_batch[r], (SIZE, SIZE)), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = model.unet(input_size= (SIZE, SIZE, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "NO_OF_TRAINING_IMAGES = len(os.listdir('train_frames/train/'))\n",
    "NO_OF_VAL_IMAGES = len(os.listdir('val_frames/val/'))\n",
    "\n",
    "NO_OF_EPOCHS = 30\n",
    "\n",
    "BATCH_SIZE = batch_size\n",
    "\n",
    "weights_path = 'weights/weights_512_leakyReLU.h5'\n",
    "\n",
    "opt = Adam(lr=1E-5, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "\n",
    "m.compile(loss=\"binary_crossentropy\",\n",
    "          optimizer=opt,\n",
    "          metrics=['acc', 'mae'])\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath=weights_path, monitor='val_loss', \n",
    "                             verbose=1, save_best_only=True, save_weights_only=True)\n",
    "\n",
    "csv_logger = CSVLogger('./log.out', append=True, separator=';')\n",
    "\n",
    "earlystopping = EarlyStopping(monitor = 'val_loss', verbose = 1,\n",
    "                              min_delta = 1e-4, patience = 2, mode = 'auto')\n",
    "\n",
    "callbacks_list = [checkpoint, csv_logger, earlystopping]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "results = m.fit_generator(train_gen, epochs=NO_OF_EPOCHS, \n",
    "                          steps_per_epoch = (NO_OF_TRAINING_IMAGES//BATCH_SIZE),\n",
    "                          validation_data=val_gen, \n",
    "                          validation_steps=(NO_OF_VAL_IMAGES//BATCH_SIZE), \n",
    "                          callbacks=callbacks_list,\n",
    "                          class_weight=class_weights)\n",
    "time_passed = time.time() - start_time\n",
    "# print('Ellapsed time: {}'.format(hms_string(time_passed))\n",
    "m.save('Model_512_LeakyReLU.h5')\n",
    "print(str(time_passed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate model on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create testing dataset\n",
    "test_frame_path = 'test_frames'\n",
    "test_mask_path  = 'test_masks'\n",
    "\n",
    "test_gen = data_gen(test_frame_path, test_mask_path, batch_size = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading test data\n",
    "image_batch, mask_batch = next(test_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.evaluate(x = image_batch,\n",
    "               y = mask_batch,\n",
    "               batch_size = 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making predictions with model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_one_mask():\n",
    "    image_batch, mask_batch = next(test_gen)\n",
    "#     print(type(image_batch))\n",
    "#     print(type(mask_batch))\n",
    "    predicted_mask_batch = m.predict(image_batch)\n",
    "    image = image_batch[0]\n",
    "#     print(type(predicted_mask_batch))\n",
    "#     print(type(image))\n",
    "    print(image.shape)\n",
    "    predicted_mask = predicted_mask_batch[0].reshape(256, 256)\n",
    "    plt.imshow(image.squeeze())\n",
    "    plt.imshow(predicted_mask, alpha=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE = (256, 256)\n",
    "predict_one_mask()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_batch, mask_batch = next(test_gen)\n",
    "pred = m.predict(image_batch)\n",
    "pred = pred > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "ax.imshow(np.reshape(mask_batch[0]*255, (256, 256)), cmap='gray')\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 2)\n",
    "ax.imshow(np.reshape(pred[0]*255, (256, 256)), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "ax.imshow(np.reshape(mask_batch[1]*255, (256, 256)), cmap=\"gray\")\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 2)\n",
    "ax.imshow(np.reshape(pred[1]*255, (256, 256)), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(train_gen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = (train_gen.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
